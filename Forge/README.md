# ğŸ”¥ Forge

> **Docker-based CLI for fine-tuning Small Language Models with Gemini as your AI co-pilot**

Forge uses **Gemini** as an intelligent agent to handle data preprocessing, hyperparameter optimization, and trainingâ€”all via **Docker containers** with GPU passthrough. Optimized for **RTX 50-series (Blackwell)**, 40-series, 30-series, and datacenter GPUs.

## âœ¨ Features

- ğŸ§  **AI-Powered** - Describe your goal in natural language, Gemini handles the rest
- âš¡ **Agentic Preprocessing** - Auto-generates and runs data preparation scripts
- ğŸ”„ **Self-Healing Training** - Automatically fixes errors and retries
- ğŸ³ **Docker-First** - Training runs in GPU-optimized containers
- ğŸ–¥ï¸ **Local Data** - Your data never leaves your machine
- ğŸ¯ **Hardware-Aware** - Auto-detects GPU and selects optimal container
- âš¡ **Unsloth Powered** - 2x faster training, 70% less VRAM

## ğŸš€ Quick Start

```bash
# 1. Install Forge CLI
cd Forge
pip install -e .
forge init

# 2. Build Docker container for your GPU
forge docker build

# 3. Prepare your data
forge prepare ./data/mydata.csv

# 4. Generate training config
forge plan "Make a coding assistant" --data ./data/processed_train.jsonl

# 5. Train via Docker
forge train

# 6. Test your model
forge inference
```

## ğŸ³ GPU Containers

| Container | GPU Support |
|-----------|-------------|
| `forge:blackwell` | RTX 5090/5080/5070 |
| `forge:ada` | RTX 4090/4080/4070 |
| `forge:ampere` | RTX 3090/3080/3070 |
| `forge:hopper` | H100/H200 |

GPU is **auto-detected** - just run `forge docker build` and it picks the right one.

## ğŸ“‹ Commands

| Command | Description |
|---------|-------------|
| `forge init` | Setup environment and configure API key |
| `forge study <path>` | Analyze dataset quality with Gemini |
| `forge prepare <path>` | **Agentic preprocessing** - auto-generate & run scripts |
| `forge plan "<goal>"` | Generate hardware-optimized training config |
| `forge train` | Execute training via Docker (self-healing) |
| `forge inference` | Interactive chat with trained model |
| `forge docker build` | Build container for your GPU |
| `forge docker detect` | Show detected GPU architecture |

## ğŸ¯ Hardware-Aware Optimization

Forge automatically detects your GPU and optimizes training:

```
ğŸ“ Planning training for: "customer service chatbot"

  GPU: NVIDIA GeForce RTX 5080
  VRAM: 16.0 GB
  Compute: 12.0 (blackwell)
  BF16: âœ“ Supported
  FP8: âœ“ Supported

ğŸ¯ Hardware Optimization:
  Architecture: blackwell
  Precision: BF16
  Recommended Model: Gemma 2B or 9B (4-bit)
```

## âš¡ Agentic Preprocessing

```bash
forge prepare ./data/english_support.csv
```

**What happens:**
1. ğŸ“Š Gemini analyzes your dataset structure
2. ğŸ§  Generates a custom preprocessing script
3. ğŸ“¦ Creates isolated sandbox venv
4. ğŸ“¥ Auto-installs dependencies with your permission
5. â–¶ï¸ Executes the script safely
6. ğŸ”„ **Self-heals** if errors occur (up to 3 retries)
7. ğŸ§¹ Cleans up sandbox, keeps processed data

**Output:** `./data/processed_train.jsonl` and `./data/processed_val.jsonl`

## ğŸ”„ Self-Healing Training

Training errors are automatically diagnosed and fixed:

```
Training fails â†’ Gemini diagnoses â†’ Config adjusted â†’ Retry
```

Auto-handled errors:
- **BFloat16 issues** - Switches to FP16
- **Out of memory** - Reduces batch size, smaller model
- **Model not found** - Tries alternative models
- **Gated models** - Prompts for HuggingFace login

## ğŸ”’ Privacy & Security

- **Data stays local** - Only metadata sent to Gemini
- **Security Sentinel** - Reviews generated scripts before execution
- **Sandboxed execution** - Scripts run in isolated venv
- **Secure credentials** - API keys stored in system keyring

## ğŸ“ Project Structure

```
your-project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_data.csv
â”‚   â”œâ”€â”€ processed_train.jsonl
â”‚   â””â”€â”€ processed_val.jsonl
â”œâ”€â”€ output/             # Trained models
â”œâ”€â”€ checkpoints/        # Training checkpoints
â””â”€â”€ forge.yaml          # Training config
```

## ğŸ› ï¸ Technical Stack

- **Training**: Unsloth + TRL + Transformers
- **Quantization**: BitsAndBytes (4-bit/8-bit)
- **AI Backend**: Google Gemini
- **Containers**: Docker with NVIDIA GPU passthrough
- **CLI**: Typer + Rich

## ğŸ“„ License

MIT

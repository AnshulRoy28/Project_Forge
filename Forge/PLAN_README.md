# ğŸ”¥ Forge - AI-Powered Local Fine-Tuning

<p align="center">
  <strong>Fine-tune language models on your local GPU using natural language.</strong>
  <br>
  <em>Powered by Google Gemini â€¢ GPU-Optimized Docker Containers â€¢ Self-Healing Training</em>
</p>

---

## ğŸ¯ What is Forge?

Forge is a **local-first CLI tool** that lets you fine-tune Small Language Models (SLMs) without writing code. Just describe what you want in plain Englishâ€”Gemini handles the rest.

```bash
forge plan "Create a customer support chatbot that's friendly and helpful"
forge train
```

That's it. No ML expertise required.

---

## âœ¨ Key Features

### ğŸ§  Gemini Integration

Forge uses **Google Gemini** as an intelligent co-pilot throughout the entire workflow:

| Stage | Gemini's Role |
|-------|---------------|
| **Data Analysis** | Analyzes your dataset, identifies issues, suggests improvements |
| **Preprocessing** | Generates custom Python scripts to clean and format your data |
| **Configuration** | Creates optimized training configs based on your goal + hardware |
| **Error Diagnosis** | Diagnoses training failures and suggests fixes |
| **Self-Healing** | Automatically repairs and retries failed operations |

**Example: Agentic Preprocessing**
```bash
forge prepare ./data/customer_support.csv
```

Gemini will:
1. Analyze your CSV structure
2. Generate a preprocessing script
3. Create an isolated sandbox
4. Execute safely with auto-retry
5. Output training-ready JSONL

### ğŸ³ GPU-Optimized Docker Containers

**The #1 pain point in ML: dependency hell.** Forge solves this with pre-built Docker containers for every major GPU architecture:

| Container | GPUs | CUDA | Status |
|-----------|------|------|--------|
| `forge:blackwell` | RTX 5090/5080/5070 | 12.8 nightly | âœ… Tested |
| `forge:ada` | RTX 4090/4080/4070 | 12.4 | âœ… Ready |
| `forge:ampere` | RTX 3090/3080/3070 | 12.1 | âœ… Ready |
| `forge:hopper` | H100/H200 | 12.4 | âœ… Ready |

**Zero GPU overhead** â€” NVIDIA Container Toolkit passes your GPU directly to the container. Native CUDA performance.

```bash
# Auto-detect GPU and run
forge docker build    # One-time build
forge docker run train  # Training with perfect deps
```

### ğŸ”„ Self-Healing Training

Training crashes? Forge diagnoses and fixes:

```
Error detected â†’ Gemini analyzes â†’ Config adjusted â†’ Retry
```

**Auto-handled issues:**
- Out of memory â†’ Reduces batch size
- BFloat16 errors â†’ Switches precision
- Missing dependencies â†’ Installs them
- Gated models â†’ Prompts for auth

### ğŸ¯ Hardware-Aware Optimization

Forge detects your GPU architecture and configures training optimally:

```
ğŸ” Detecting GPU...
  GPU: NVIDIA GeForce RTX 5080
  VRAM: 16.0 GB
  Compute: 12.0 (Blackwell)
  BF16: âœ“ Supported
  FP8: âœ“ Supported

ğŸ¯ Recommended Settings:
  Precision: BF16 (native to Blackwell)
  Optimizer: adamw_8bit (saves 2GB VRAM)
  Batch Size: 8
```

---

## ğŸš€ Quick Demo

```bash
# 1. Clone and enter
git clone https://github.com/yourrepo/forge.git && cd forge

# 2. Set your Gemini API key
set GEMINI_API_KEY=your_key_here   # Windows
export GEMINI_API_KEY=your_key_here  # Linux/Mac

# 3. Build your GPU-specific container
forge docker build

# 4. Analyze and preprocess your data
forge docker run study ./data/my_data.csv
forge docker run prepare ./data/my_data.csv

# 5. Generate training config with natural language
forge docker run plan "Make a helpful coding assistant"

# 6. Train!
forge docker run train

# 7. Test your model
forge docker run test
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User CLI                              â”‚
â”‚   forge plan | forge prepare | forge train | forge test      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Gemini Brain ğŸ§                           â”‚
â”‚  â€¢ Data analysis    â€¢ Script generation                      â”‚
â”‚  â€¢ Config planning  â€¢ Error diagnosis                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GPU-Optimized Docker Containers ğŸ³              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚Blackwell â”‚ â”‚   Ada    â”‚ â”‚  Ampere  â”‚ â”‚  Hopper  â”‚       â”‚
â”‚  â”‚RTX 50xx  â”‚ â”‚RTX 40xx  â”‚ â”‚RTX 30xx  â”‚ â”‚  H100    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Training Engine âš¡                        â”‚
â”‚  â€¢ Unsloth (2x speed, 70% less VRAM)                        â”‚
â”‚  â€¢ BF16/TF32 precision                                       â”‚
â”‚  â€¢ Gradient checkpointing                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Commands Overview

| Command | Description |
|---------|-------------|
| `forge init` | Setup environment, configure API key |
| `forge study <data>` | Analyze dataset with Gemini |
| `forge prepare <data>` | Auto-preprocess (agentic) |
| `forge plan "<goal>"` | Generate training config |
| `forge train` | Start self-healing training |
| `forge test` | Interactive model testing |
| `forge docker detect` | Show GPU architecture |
| `forge docker build` | Build container for your GPU |
| `forge docker run <cmd>` | Run command in container |

---

## ğŸ”’ Privacy & Security

- âœ… **Data stays local** â€” Only metadata sent to Gemini
- âœ… **Sandboxed execution** â€” Scripts run in isolated venvs
- âœ… **Security Sentinel** â€” Reviews generated code before execution
- âœ… **Secure credentials** â€” API keys in system keyring

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| AI Brain | Google Gemini |
| Training | Unsloth, TRL, Transformers |
| Quantization | BitsAndBytes |
| Containers | Docker + NVIDIA Container Toolkit |
| CLI | Typer + Rich |

---

## ğŸ“ˆ Roadmap

- [x] Core CLI commands
- [x] Gemini integration for all stages
- [x] Docker containers for all GPU architectures
- [x] Self-healing training
- [x] Hardware-aware config generation
- [ ] Web UI for monitoring
- [ ] Multi-GPU training
- [ ] Cloud deployment support
- [ ] Model marketplace integration

---

## ğŸ† Built for Google Gemini Hackathon

Forge demonstrates how **Gemini can orchestrate complex ML workflows** â€” turning natural language into trained models with minimal friction.

---

<p align="center">
  <strong>ğŸ”¥ Forge â€” Because fine-tuning should be as easy as asking.</strong>
</p>
